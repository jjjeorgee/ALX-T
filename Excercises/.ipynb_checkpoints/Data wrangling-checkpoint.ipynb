{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdd7182",
   "metadata": {},
   "source": [
    "## This exercise outlines the entire data wrangling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91675b3",
   "metadata": {},
   "source": [
    "### Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9d3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53738c94",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract all contents from zip file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marchive.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m myzip:\n\u001b[0;32m      3\u001b[0m     myzip\u001b[38;5;241m.\u001b[39mextractall()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1248\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive.zip'"
     ]
    }
   ],
   "source": [
    "# Extract all contents from zip file\n",
    "with zipfile.ZipFile('archive.zip', 'r') as myzip:\n",
    "    myzip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV (comma-separated) file into DataFrame\n",
    "df = pd.read_csv('online-job-postings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef9c3b",
   "metadata": {},
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8669560",
   "metadata": {},
   "source": [
    "#### Visual assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eec02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b662eb4",
   "metadata": {},
   "source": [
    "##### issues\n",
    "- missing values (NaN)\n",
    "- start date inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e5f50",
   "metadata": {},
   "source": [
    "#### Programmatic Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37155509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e629735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561476e",
   "metadata": {},
   "source": [
    "- Fix nondescriptive column headers (ApplicationP, AboutC, RequiredQual ... and also JobRequirment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.StartDate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546e0ec",
   "metadata": {},
   "source": [
    "#### More problems with our Dataset\n",
    "Duplicate representation of ear and month data. For tidy, we need oneday, one month and one year so if we can update the data in one place.\n",
    "\n",
    "Two types of observational units in this dataset: job posting data and company data. To make this tidy, we would have two tables: Job Posting data with everything except the AboutC and then a second Company table with only the company column and an About Company column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43c3a7",
   "metadata": {},
   "source": [
    "### Clean\n",
    "\n",
    "#### Define\n",
    "- Select all records in the StartDatecolumn that have varying values, and replace them with \"ASAP\"\n",
    "\n",
    "- Select all Nondescriptive and misspelled column headers, and replace them with full words/ more descriptive words.\n",
    "\n",
    "> we will not bother with replacing the NaN values because of the nature of the dataset.\n",
    "\n",
    "> we don't want spaces in the column headers because we can't access columns using dot notation in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43aca81",
   "metadata": {},
   "source": [
    "#### Programmatic cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb17cc",
   "metadata": {},
   "source": [
    "#### Issue 1\n",
    "\n",
    "#### Define\n",
    "- Select all Nondescriptive and misspelled column headers, and replace them with full words/ more descriptive words.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283a352",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29067fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.rename(columns = {'ApplicationP' : 'ApplicationProcedure',\n",
    "                                'AboutC' : 'AboutCompany',\n",
    "                                'RequiredQual' : 'RequiredQualifications',\n",
    "                                'JobRequirment' : 'JobRequirement'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d89044",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0de0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1c6fa",
   "metadata": {},
   "source": [
    "#### Issue 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454955c",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce749ffb",
   "metadata": {},
   "source": [
    "- Select all records in the StartDatecolumn that have varying values, and replace them with \"ASAP\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273365a",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd19e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.StartDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asap_list = ['Immediately', 'As soon as possible', 'Upon hiring',\n",
    "             'Immediate', 'Immediate employment', 'As soon as possible.', 'Immediate job opportunity',\n",
    "             '\"Immediate employment, after passing the interview.\"',\n",
    "             'ASAP preferred', 'Employment contract signature date',\n",
    "             'Immediate employment opportunity', 'Immidiately', 'ASA',\n",
    "             'Asap', '\"The position is open immediately but has a flexible start date depending on the candidates earliest availability.\"',\n",
    "             'Immediately upon agreement', '20 November 2014 or ASAP',\n",
    "             'immediately', 'Immediatelly',\n",
    "             '\"Immediately upon selection or no later than November 15, 2009.\"',\n",
    "             'Immediate job opening', 'Immediate hiring', 'Upon selection',\n",
    "             'As soon as practical', 'Immadiate', 'As soon as posible',\n",
    "             'Immediately with 2 months probation period',\n",
    "             '12 November 2012 or ASAP', 'Immediate employment after passing the interview',\n",
    "             'Immediately/ upon agreement', '01 September 2014 or ASAP',\n",
    "             'Immediately or as per agreement', 'as soon as possible',\n",
    "             'As soon as Possible', 'in the nearest future', 'immediate',\n",
    "             '01 April 2014 or ASAP', 'Immidiatly', 'Urgent',\n",
    "             'Immediate or earliest possible', 'Immediate hire',\n",
    "             'Earliest  possible', 'ASAP with 3 months probation period.',\n",
    "             'Immediate employment opportunity.', 'Immediate employment.',\n",
    "             'Immidietly', 'Imminent', 'September 2014 or ASAP', 'Imediately']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be26b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in asap_list:\n",
    "    df_clean.StartDate.replace(phrase, 'ASAP', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fa087",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.StartDate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in asap_list:\n",
    "    assert phrase not in df_clean.StartDate.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378cb12",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacb925",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ASAP start dates \n",
    "asap_counts = df_clean.StartDate.value_counts()['ASAP']\n",
    "asap_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty_counts = df_clean.StartDate.count()\n",
    "non_empty_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "asap_counts/non_empty_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "labels = np.full(len(df_clean.StartDate.value_counts()), \"\", dtype=object)\n",
    "labels[0] = 'ASAP'\n",
    "df_clean.StartDate.value_counts().plot(kind=\"pie\", labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
